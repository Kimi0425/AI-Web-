Water   Research   189   (2021)   116657  Contents   lists   available   at   ScienceDirect  Water   Research  journal   homepage:   www.elsevier.com/locate/watres  Development   of   an   ensemble   of   machine   learning   algorithms   to  model   aerobic   granular   sludge   reactors  Mohamed   Sherif   Zaghloul   a , ∗ ,   Oliver   Terna   Iorhemen   b ,   Rania   Ahmed   Hamza   c ,  Joo   Hwa   Tay   a , # ,   Gopal   Achari   a  a   Department   of   Civil   Engineering,   University   of   Calgary,   2500   University   Drive   NW,   Calgary,   AB.,   Canada.   T2N   1N4  b   Department   of   Civil   and   Environmental   Engineering,   University   of   Alberta  c   Department   of   Civil   Engineering,   Ryerson   University  a   r   t   i   c   l   e   i   n   f   o  Article   history:  Received   11   August   2020  Revised   17   October   2020  Accepted   18   November   2020  Available   online   19   November   2020  Keywords:  Machine   Learning  Artificial   neural   networks  Adaptive   Neuro-Fuzzy   Inference   Systems  Support   Vector   Regression  Aerobic   granular   sludge  Sequencing   Batch   Reactors  a   b   s   t   r   a   c   t  Machine   learning   models   provide   an   adaptive   tool   to   predict   the   performance   of   treatment   reactors   under  varying   operational   and   influent   conditions.   Aerobic   granular   sludge   (AGS)   is   still   an   emerging   technology  and   does   not   have   a   long   history   of   full-scale   application.   There   is,   therefore,   a   scarcity   of   long-term   data  in   this   field,   which   impacted   the   development   of   data-driven   models.   In   this   study,   a   machine   learning  model   was   developed   for   simulating   the   AGS   process   using   475   days   of   data   collected   from   three   lab-  based   reactors.   Inputs   were   selected   based   on   RReliefF   ranking   after   multicollinearity   reduction.   A   five-  stage   model   structure   was   adopted   in   which   each   parameter   was   predicted   using   separate   models   for   the  preceding   parameters   as   inputs.   An   ensemble   of   artificial   neural   networks,   support   vector   regression   and  adaptive   neuro-fuzzy   inference   systems   was   used   to   improve   the   models’   performance.   The   developed  model   was   able   to   predict   the   MLSS,   MLVSS,   SVI 5   ,   SVI 30   ,   granule   size,   and   effluent   COD,   NH 4  -N,   and  PO 4  3 −   with   average   R 2  ,   nRMSE   and   sMAPE   of   95.7%,   0.032   and   3.7%   respectively.  © 2020 Elsevier Ltd. All rights reserved.  1.   Introduction  Aerobic   granular   sludge   (AGS)   is   a   promising   biological   wastew-  ater   treatment   technology   that   has   shown   excellent   performance  in   laboratories   for   the   treatment   of   domestic   and   high-strength  wastewater   and   is   starting   to   be   applied   in   full-scale   wastewater  treatment   plants   (WWTPs)   ( Pronk   et   al.,   2015 ;   Zheng   et   al.,   2020 ).  AGS   has   certain   advantages   over   conventional   activated   sludge  (CAS)   in   terms   of   lower   reactor   footprint,   higher   capacity   for   or-  ganic   loading   and   simultaneous   removal   of   nutrients   and   organ-  ics   ( He   et   al.,   2020 ).   The   compact   structure   of   the   biomass   gran-  ules   gives   the   reactor   higher   resilience   against   shock   loads   and  toxic   wastewater   and   provides   better   biomass   retention   due   to   the  enhanced   settling   properties   ( Franca   et   al.,   2018 ;   Nancharaiah   &  Reddy,   2018 ).  Although   AGS   has   consistently   shown   promise   in   terms   of   per-  formance,   the   operation   of   AGS   bioreactors   is   challenging   due   to  the   large   number   of   factors   affecting   the   process   ( Wilén   et   al.,  2018 ).   The   characteristics   of   the   influent   wastewater,   biomass  ∗   Corresponding   Author.  E-mail   address:   mohamed.abdelsamie@ucalgary.ca   (M.S.   Zaghloul).  #   Deceased.  properties   within   the   reactor   and   operational   conditions   all   play  a   significant   role   in   the   removal   efficiency   of   the   reactor.   Addition-  ally,   these   factors   are   interconnected   and   have   complex   nonlinear  relationships   ( Khan   et   al.,   2013 ).   Influent   characteristics   and   the  mode   of   operation   of   the   sequencing   batch   reactor   (SBR)   play   a  significant   role   in   the   biomass   microbial   culture,   which   in   turn   af-  fects   the   integrity   of   the   granule   structure   and   settling   ability.   The  settling   ability   of   biomass   is   also   affected   by   the   settling   time,   vol-  umetric   exchange   ratio,   and   discharge   time.   At   the   end   of   the   set-  tling   time,   slow   settling   biomass   that   does   not   settle   below   the   ef-  fluent   port   gets   washed   out   of   the   reactor   during   the   decant   phase,  leaving   the   faster   settling   granules   inside   the   reactor   ( Qin   et   al.,  20  04 ;   Wang   et   al.,   20  04 ).   This   also   affects   the   concentration   of  biomass   left   inside   the   reactor   after   every   cycle   of   operation,   which  provides   seed   for   new   granule   formation   and,   therefore,   directly   af-  fects   the   level   of   organics   and   nutrients   removal.   A   certain   aeration  time   is   necessary   for   aerobic   degradation   of   organics,   nitrification  and   for   providing   the   required   shear   force   that   triggers   the   granu-  lation   process   in   the   biomass   flocs,   the   latter   being   the   governing  factor   ( Hamza   et   al.,   2018 ).   Other   factors   that   affect   the   AGS   pro-  cess   include   the   influent   pH,   volumetric   exchange   ratio,   hydraulic  retention   time   (HRT),   and   temperature   ( Khan   et   al.,   2013 ).   Sudden  changes   to   these   factors   can   lead   to   the   failure   of   the   structural   in-  tegrity   of   the   granules   and   the   washout   of   the   biomass   out   of   the  https://doi.org/10.1016/j.watres.2020.116657  0043-1354/© 2020 Elsevier Ltd. All rights reserved.
M.S.   Zaghloul,   O.T.   Iorhemen,   R.A.   Hamza   et   al.   Water   Research   189   (2021)   116657  reactor,   resulting   in   the   reactor   failing   to   meet   the   required   effluent  quality.   Since   these   factors   do   continue   to   change,   the   operation   of  an   AGS   system   is   challenging   and   requires   careful   monitoring.  A   tool   that   can   simulate   AGS   reactors   considering   all   previ-  ously   mentioned   factors   would   help   alleviate   some   of   this   chal-  lenge.   Such   a   tool   can   provide   operators   with   the   ability   to   pre-  dict   the   reactor   performance   and   adapt   as   the   quality   of   influent  wastewater   changes.  There   are   several   studies   in   the   literature   that   present   physical  models   for   AGS   reactors   ( Baeten   et   al.,   2019 ;   Ni   &   Yu,   2010 ).   Phys-  ical   AGS   models   utilize   the   biofilm   model   to   simulate   the   diffu-  sion   of   the   substrate   into   the   granules   and   Activated   Sludge   Mod-  els   (ASM)   based   equations   to   simulate   the   kinetics   of   the   biolog-  ical   process   ( Cui   et   al.,   2020 ).   Many   restrictions   and   assumptions  have   to   be   made   to   be   able   to   develop   physical   models   without   be-  ing   overly   complicated   ( Ni   &   Yu,   2010 ).   The   calibrated   kinetic   and  stoichiometric   parameters   will   change   with   any   change   in   opera-  tion   or   influent   wastewater,   making   it   challenging   to   use   physical  models   for   process   control   ( Baeten   et   al.,   2018 ).   Physical   models,  however,   are   excellent   for   understanding   the   biological   processes,  conversion   rates,   and   for   studying   the   factors   affecting   the   process  performance.  Machine   learning   provides   an   excellent   alternative   to   physi-  cal   models   for   predicting   reactor   performance   and   process   con-  trol.   Data-driven   models   can   overcome   the   need   for   continuous  re-calibration   of   physical   models.   They   are   more   adaptive   and   can  learn   from   new   data   that   is   collected   as   the   process   continues  to   run   ( El-Din   et   al.,   2004 ).   The   use   of   machine   learning   for   AGS  modelling   is   still   not   as   studied   as   physical   models   ( Baeten   et   al.,  2019 ).   Artificial   neural   networks   (ANN)   were   used   to   simulate   the  AGS   process   in   a   simple   model   structure   where   only   chemical   oxy-  gen   demand   (COD)   and   total   nitrogen   (TN)   removals   were   pre-  dicted   with   an   R 2   of   0.9   and   0.81   ( Gong   et   al.,   2018 ).   Single   hid-  den   layer   ANNs   were   used   to   predict   the   effluent   COD   using   six  inputs,   resulting   in   an   R 2   of   0.91   ( Mahmod   &   Wahab,   2017 ).   An-  other   AGS   model   was   developed   using   single   hidden   layer   feed-  forward   ANNs   using   eight   inputs   to   predict   the   effluent   COD,   NH 4  -  N,   and   TN   with   an   R 2   of   0.9988,   0.9997,   and   0.9991,   respectively  ( Liang   et   al.,   2020 ).   A   more   comprehensive   model   structure   was  developed   using   feed-forward   multi-layer   ANNs   to   simulate   the  full   AGS   process,   including   the   prediction   of   biomass   characteris-  tics   and   the   removal   rates   of   COD,   ammonia,   and   phosphates,   with  a   minimum   prediction   R 2   of   99%   ( Zaghloul   et   al.,   2018 ).   Adaptive  neuro-fuzzy   inference   systems   (ANFIS)   and   support   vector   regres-  sion   (SVR)   were   investigated   as   alternative   algorithms   to   ANN,   con-  cluding   that   SVR   provided   comparable   results   to   ANN   with   a   min-  imum   R 2   of   0.997,   while   ANFIS   provided   lower   prediction   accuracy  than   ANN   and   SVR   with   a   minimum   R 2   of   0.815   when   simulating  AGS   reactors   ( Zaghloul   et   al.,   2020 ).  Aside   from   modelling   AGS,   machine   learning   has   shown   excel-  lent   performance   in   simulating   other   wastewater   treatment   pro-  cesses   such   as   CAS,   showing   the   potential   application   of   ma-  chine   learning   in   forecasting   and   process   control   ( Corominas   et   al.,  2018 ).   An   ANN   model   was   successfully   used   for   modelling   the   BOD  and   TSS   removal   in   a   full-scale   CAS   process   using   single   input-  single   output   models   with   an   R 2   of   0.665   and   0.542,   respectively  ( Hamed   et   al.,   2004 ).   ANN   was   also   used   for   the   development  of   software   sensors   that   predict   the   effluent   TN,   TP   and   COD   for  a   real-time   remote   monitoring   system   in   another   full-scale   CAS  treatment   plant,   with   an   R 2   of   0.952,   0.934,   and   0.921,   respectively  ( Lee   et   al.,   2008 ).   SVR   was   used   to   predict   the   removal   of   COD,  ammonia,   and   nitrates   in   a   CAS   process   using   microbial   commu-  nity   data   with   an   R 2   of   0.9501,   0.7936,   and   0.8916,   respectively  ( Seshan   et   al.,   2014 ).   ANN   and   SVR   were   compared   for   the   predic-  tion   of   effluent   TN   in   a   CAS   process   treating   food   waste   leachate,  showing   that   both   algorithms   performed   similarly   where   the   R 2  was   0.47   and   0.46   respectively,   however,   the   SVR   suffered   from  overfitting   where   the   training   R 2   was   1.00   ( Guo   et   al.,   2015 ).   AN-  FIS   was   compared   to   SVR   for   predicting   the   removal   of   TKN   in  a   full-scale   BNR   plant,   where   SVR   provided   better   performance  than   ANFIS   with   R 2   values   of   0.85   and   0.91,   respectively   ( Manu   &  Thalla,   2017 ).  The   studies   above   concluded   that   ANN,   SVR   and   ANFIS   are  capable   of   simulating   various   biological   treatment   processes   in  WWTPs.   It   was   also   observed   that   while   ANN   provided   reliable  results,   it   required   the   largest   training   datasets   to   provide   good  quality   modelling.   SVR   was   reported   to   provide   unique   solutions  to   regression   problems   and   not   as   likely   to   get   trapped   in   local  error   minima   during   error   optimization   as   ANN,   but   it   is   hard   to  interpret   the   final   model   formulation,   and   the   computational   re-  quirements   increase   with   larger   datasets   ( Karamizadeh   et   al.,   2014,  September ).   ANFIS   models   can   be   relatively   easier   to   interpret   than  ANN   and   SVR,   but   the   number   of   fuzzy   rules   increases   exponen-  tially   with   the   number   of   input   variables   and   input   membership  functions   ( Stathakis   et   al.,   2006 ).   Ye   et   al.   (2020)   detailed   the   char-  acteristics,   advantages   and   limitations   of   several   algorithms,   in-  cluding   the   ones   used   in   this   study   ( Ye   et   al.,   2020 ).   They   showed  that:   (1)   ANNs   are   accurate   but   have   the   risk   of   overfitting   and  harder   to   find   the   best   architecture.   (2)   SVR   works   well   with   noisy  data   and   does   not   require   as   much   training   data   but   needs   higher  computation   power   that   other   algorithms.   (3)   ANFIS   can   optimally  solve   nonlinear   problems,   but   it   is   difficult   to   find   the   best   model  structure.  Machine   learning   ideally   requires   large   datasets   for   training  the   algorithms   ( Liu   et   al.,   2017 ).   Databases   from   AGS   WWTPs   are  still   not   large   enough   for   conventional   machine   learning   simula-  tions.   Small   datasets   are   challenging   when   used   for   training   ma-  chine   learning   models,   i.e.   the   training   process   becomes   highly   af-  fected   by   data   quality   issues,   dimensionality,   and   multicollinearity  ( Shaikhina   &   Khovanova,   2017 ).   Additionally,   small   datasets   with  high   dimensionality   increase   the   required   level   of   model   com-  plexity   to   achieve   reasonable   prediction   accuracies   ( Wójcik   &   Kur-  dziel,   2019 ).   Data   pre-processing   and   feature   selection   play   an   im-  portant   role   in   handling   outliers   and   gaps,   normalizing   features,  and   reducing   dimensionality   and   multicollinearity   in   the   dataset,  which   improves   the   model   training   and   final   performance.  This   work   presents   a   modelling   approach   for   AGS   reactors   when  only   small   datasets   are   available.   Data   were   pre-processed   and  cleaned,   then   feature-selection   was   performed   using   the   variance  inflation   factor   (VIF)   for   reducing   multicollinearity   and   the   RReliefF  algorithm   for   ranking   inputs.   A   combination   of   ANN,   SVR   and   AN-  FIS   algorithms   was   used   via   different   ensemble   techniques,   and   the  best   performing   technique   was   used   for   the   final   model.   A   multi-  stage   model   structure   was   developed   to   provide   stepwise   predic-  tions   where   outputs   of   each   stage   get   added   to   the   potential   pool  of   inputs   for   the   following   stage.   The   purpose   of   this   model   is   to  provide   a   tool   that   can   predict   the   biomass   characteristics   inside  AGS   reactors,   effluent   characteristics   (concentrations   of   COD,   NH 4  -  N,   and   PO 4  3 − ),   and   potential   failure   to   meet   user-defined   treat-  ment   requirements.  2.   Methods  2.1.   Experimental   Setup  Three   SBRs   were   set   up   and   operated   to   collect   the   required  data   for   this   study.   Reactor   R1   had   a   diameter   of   89   mm,   and   a  working   volume   of   4.5   L.   Reactors   R2   and   R3   had   a   diameter   of  150   mm,   and   a   working   volume   of   19   L.   Fig.   1   shows   the   general  setup   of   the   reactors.  The   SBR   operation   was   automated   with   scheduled   times   for   fill,  idle,   aeration   (reaction),   settling,   and   draw   (decant).   Table   1   shows  2
M.S.   Zaghloul,   O.T.   Iorhemen,   R.A.   Hamza   et   al.   Water   Research   189   (2021)   116657  Fig.   1.   SBR   reactors   setup.  Table   1  Reactor   operation   parameters.  Parameter   Reactor   R1   Reactor   R2   Reactor   R3  Fill   Time   (min)   6   – 7   6   – 8   60  Idle   Time   (min)   0   – 5   1   – 3   2  Aeration   Time   (min)   180   – 182   180   – 222   145   – 172  Settling   Time   (min)   3   – 15   8   – 30   5   – 30  Decanting   Time   (min)   1   – 6   1   1  Superficial   Air   Velocity   (cm/s)   1.6   – 4   2.11   3  the   cycle   times   and   superficial   air   velocity   used   for   the   duration   of  the   data   collection   period.   Aeration   was   provided   using   air   com-  pressors   and   controlled   using   Cole-Parmer   airflow   meters   and   reg-  ulators.   Air   was   diffused   into   the   reactor   using   Paintair   fine   bubble  ceramic   diffusers   (AS4).   Masterflex   peristaltic   pumps   were   used   for  feeding   the   reactors.  The   reactors   were   operated   using   synthetic   wastewater   pre-  pared   as   detailed   in   ( Tay   et   al.,   2002 ).   The   main   carbon,   nitrogen  and   phosphorus   sources   were   sodium   acetate,   ammonium   chloride,  monopotassium   and   dipotassium   phosphate,   respectively.   Return  activated   sludge   (RAS)   was   procured   from   the   Pine   Creek   wastew-  ater   treatment   plant   for   seeding   the   granulation   process.   The   reac-  tors   were   run   at   a   stable   temperature   of   18 ± 2 ° C.   Influent,   effluent  and   biomass   samples   were   collected   daily.   Mixed   liquor   suspended  solids   (MLSS),   mixed   liquor   volatile   suspended   solids   (MLVSS),   5-  minute   sludge   volumetric   index   (SVI 5  )   and   30-minute   SVI   (SVI 30  )  were   measured   according   to   standard   methods   ( Rice   et   al.,   2017 ).  The   United   States   Environmental   Protection   Agency   (USEPA)   reac-  tor   digestion   method   was   adopted   for   the   measurement   of   COD  using   a   HACH   DR-2400   spectrophotometer.   The   salicylate   method  was   used   to   measure   ammonia   with   TNT   830,   831,   832   and   833  kits.   Ion   chromatography   was   used   to   measure   reactive   phosphate  using   a   Metrohm   Compact   IC   Flex   based   on   the   Standard   Methods  for   the   Examination   of   Water   and   Wastewater   ( Rice   et   al.,   2017 ).  Laser   particle   size   analysis   was   used   to   measure   the   granule   size  (Malvern   MasterSizer   Series   20  0  0).  2.2.   Model   Structure  This   study   adopted   a   5-stage   model   structure   where   each   of   the  stages   2   to   5   is   predicted   using   the   preceding   stages   as   potential  inputs,   as   shown   in   Fig.   2 .   The   multi-stage   model   structure   is   de-  signed   to   simulate   the   cause-effect   process   in   AGS   reactors,   where  the   influent   characteristics   and   operational   parameters   affect   the  biomass   concentration   due   to   growth   and   decay   of   the   microbial  community.   The   biomass   concentration   and   the   SBR   operation   di-  rectly   affect   the   biomass   settling   properties,   which   in   turn   affects  the   granule   growth.   All   the   previous   parameters   and   interactions  affect   the   removal   efficiency   and   the   effluent   wastewater   quality.  Each   of   the   parameters   in   stages   2   -   5   were   predicted   using   a   sep-  arate   model,   except   for   the   F/M   ratio   that   was   calculated   using   the  influent   organics   and   biomass   concentrations   then   added   as   input  for   stages   4   and   5.   The   multi-stage   structure   also   adds   versatility  during   model   development   as   it   allows   using   different   inputs   for  each   output.  In   this   study,   three   algorithm   alternatives   were   individually  used   for   simulating   the   AGS   process:   ANN,   SVR   and   ANFIS.   The  outputs   of   individual   models   were   combined   as   inputs   to   ensem-  ble   algorithms   using   five   different   alternative   methods:   ANN,   SVR,  ANFIS,   arithmetic   mean   (E-AVG),   and   weighted   average   (E-WAVG).  In   total,   each   output   was   predicted   eight   times   using   the   individ-  ual   and   ensemble   alternatives.   The   best   performing   algorithm   out  of   the   eight   alternatives   was   chosen   for   the   final   model.   The   en-  semble   algorithms   were   denoted   with   the   prefix   “E-”.   Fig.   3   shows  the   algorithm   choice   approach.  The   dataset   of   475   days   was   divided   into   404   days   for   develop-  ing   the   models   and   71   days   for   evaluation.   The   evaluation   dataset  was   completely   isolated   and   was   only   used   after   the   models   were  trained   and   chosen.   Fig.   4   shows   the   data   divisions   for   the   algo-  rithms   used   in   this   study.   The   model   development   data   (404   days)  was   divided   according   to   the   requirements   of   the   algorithm   being  Stage 1 Influent NH 4   -N PO 43- pH OLR HRT Temp. Reactor Vol. Upflow Air Vel. Settling Time Stage 2 Biomass MLSS MLVSS Stage 3 Biomass SVI 5 SVI 30 F/M Ratio Stage 4 Biomass Granule Size Stage 5 Effluent COD NH 4   -N PO 43-  Fig.   2.   Multi-stage   model   structure   (stage   1   contains   parameters   after   multicollinearity   reduction).  3
M.S.   Zaghloul,   O.T.   Iorhemen,   R.A.   Hamza   et   al.   Water   Research   189   (2021)   116657  Fig.   3.   Algorithm   alternatives   flowchart:   each   model   output   is   predicted   using  eight   different   algorithms.  trained.   The   ANN   and   E-ANN   models   had   a   data   division   scheme   of  70%   for   training,   15%   for   test   and   15%   for   validation,   which   corre-  sponded   to   284,   60   and   60   days,   respectively.   The   SVR   and   E-SVR  models   utilized   the   full   404   days   for   training.   The   ANFIS   and   E-  ANFIS   models   used   85%   of   the   data   for   training   and   15%   for   valida-  tion,   which   corresponded   to   344   and   60   days,   respectively.   The   E-  AVG   and   E-WAVG   ensembles   are   not   machine   learning   algorithms;  thus,   they   did   not   require   training   and   validation.  2.3.   Data   Pre-Processing  The   dataset   collected   for   this   study   consisted   of   475   days.  Datasets   used   for   training   machine   learning   algorithms   need   to   un-  dergo   a   cleaning   process   that   mainly   removes   outliers,   fills   missing  points,   randomizes   the   dataset,   and   normalizes   all   the   data   fea-  tures   to   the   same   scale.   In   this   study,   outliers   were   removed   dur-  ing   data   collection,   and   missing   data   points   were   filled   using   linear  regression   imputation   ( Lakshminarayan   et   al.,   1999 ).  Randomization   is   done   to   remove   the   effect   of   phased   opera-  tion   and   the   use   of   multiple   reactors   when   the   dataset   is   split   into  training   and   evaluation   datasets.   The   statistical   properties   of   the  training   and   evaluation   datasets   must   be   as   close   as   possible   to  ensure   proper   evaluation   of   the   models.   Table   2   shows   the   maxi-  mum,   minimum,   mean   and   coefficient   of   variation   for   the   training  and   evaluation   datasets.  Following   randomization,   each   feature   in   the   training   dataset   is  normalized   to   the   scale   of   (0   -   1)   by   dividing   the   feature   by   its  maximum   value.   The   evaluation   dataset   was   normalized   using   the  training   maximum   to   keep   the   evaluation   dataset   unseen   during  the   model   development;   therefore,   the   normalized   values   might  slightly   exceed   one   if   the   maximum   of   the   evaluation   dataset   was  higher   than   that   of   the   training   dataset.  2.4.   Feature   Selection  The   choice   of   model   inputs   has   a   significant   effect   on   model  performance.   The   dataset   collected   contained   input   parameters  that   are   correlated   at   varying   degrees   and   contributed   differently  to   each   of   the   outputs.   Each   output   had   a   pool   of   parameters   to  choose   its   inputs   from   using   feature   selection   methods   such   as  multicollinearity   reduction   and   RReleifF   algorithms.  Linearly   correlated   input   parameters   reduce   the   orthogonality  of   the   model,   which   is   also   known   as   multicollinearity   ( Alin,   2010 ).  Multicollinearity   is   a   source   of   overfitting   during   training   and   re-  sults   in   models   with   low   reliability   ( Read   &   Belsley,   1994 ).   The  level   of   multicollinearity   in   a   set   of   parameters   can   be   measured  using   the   variance   inflation   factor   (VIF),   as   shown   in   Eq.   (1) .   It   is  generally   accepted   that   VIF   values   of   5   and   below   are   accepted   for  regression   problems.   If   the   VIF   is   larger   than   5,   the   parameter   with  the   highest   VIF   is   removed,   and   the   test   is   repeated   till   the   maxi-  mum   VIF   is   5   or   less.  V   IF   =   1  1   −   R 2  i  (1)  After   multicollinearity   is   reduced   and   redundant   parameters   are  removed,   the   remaining   parameters   were   sorted   according   to   a  weight   calculated   for   each   parameter   using   the   RReliefF   algorithm.  The   RReliefF   algorithm   is   one   of   the   filter   methods   for   feature   se-  lection   that   assigns   weights   to   input   parameters   based   on   their  effect   on   the   output   using   the   k-nearest   neighbours   approach   for  input-output   instances,   where   higher   weights   correspond   to   more  important   inputs   ( Urbanowicz   et   al.,   2018 ).   Weights   are   calculated  based   on   three   probabilities   at   the   nearest   instances:   a   different   in-  put   value   at   nearest   outputs,   a   different   output   value   at   nearest   in-  puts,   and   a   different   output   value   when   there   is   a   difference   in   the  input   value.   Detailed   mathematical   formulation   and   the   algorithm  structure   can   be   found   in   ( Robnik-Šikonja   &   Kononenko,   1997 ).   In-  puts   that   are   more   consistent   with   the   nearest   neighbours   in   ex-  plaining   the   variation   in   outputs   receive   higher   weights.   The   RRe-  liefF   algorithm,   being   one   of   the   filter   methods,   carries   the   advan-  tage   that   it   is   not   affected   by   the   induction   algorithms   applied   to  the   raw   data   (data   pre-processing)   ( Urbanowicz   et   al.,   2018 ).   This  allows   the   chosen   inputs   to   be   used   with   different   machine   learn-  ing   algorithms   with   confidence.  Full dataset (475 days) Development (404 days) NN Training (284 days) Test (60 days) Validation (60 days) E-NN Training (284 days) Test (60 days) Validation (60 days) ANFIS Training (344 days) Validation (60 days) E-ANFIS Training (344 days) Validation (60 days) SVR Training (404 days) E-SVR Training (404 days) Evaluation (71 days)  Fig.   4.   Data   division   for   model   development   and   evaluation.  4
M.S.   Zaghloul,   O.T.   Iorhemen,   R.A.   Hamza   et   al.   Water   Research   189   (2021)   116657  Table   2  Statistical   properties   of   the   training   and   evaluation   dataset.  Parameter  Max.   Min.   Mean   Coef.   Of   Var.  Train.   Eval.   Train.   Eval.   Train.   Eval.   Train.   Eval.  Influent   COD   (mg/L)   8758   7445   1287   1518   3352   3069   0.56   0.51  Influent   NH 4   -N   (mg/L)   234   201   53   68   129   135   0.32   0.28  Influent   PO 4   3 −   (mg/L)   124   83   3   6   48   47   0.38   0.33  Influent   Flowrate   (L/d)   74.81   74.81   11.03   11.03   62.63   60.95   0.28   0.31  Volume   (L)   19   19   4.5   4.5   17.49   17.16   0.25   0.28  Influent   pH   9.06   8.47   0.00   6.62   7.17   7.19   0.08   0.04  OLR   (kg   COD/m 3   )   33.08   26.87   3.48   4.47   11.06   9.70   0.66   0.57  HRT   (h)   9.67   9.67   5.92   5.92   7.69   7.79   0.10   0.09  Exchange   Ratio   (%)   0.56   0.56   0.35   0.35   0.50   0.50   0.09   0.09  Superficial   Air   Vel   (cm/s)   3   3   1.56   1.56   2.51   2.53   0.18   0.18  Temperature   ( ° C)   24.1   23.7   12.4   14.3   20.5   20.5   0.09   0.09  Settling   time   (min)   30   30   3   3   13.14   14.17   0.41   0.40  Aeration   time   (min)   221   221   163   163   187   185   0.13   0.13  MLSS   (mg/L)   25157   24411   779   2485   7966   7446   0.66   0.61  MLVSS   (mg/L)   19303   18675   523   2015   6329   6023   0.61   0.57  SVI 5   (mL/g)   446   241   20   22   113   117   0.56   0.49  SVI 30   (mL/g)   278   137   18   21   73   75   0.48   0.39  Granule   Size   ( μ m)   952   930   66   76   440   468   0.47   0.44  F/M   Ratio   12.14   4.21   0.54   0.92   2.07   1.89   0.51   0.34  Effluent   COD   (mg/L)   4227   2940   0   9   210   136   3.03   3.11  Effluent   NH 3   -N   (mg/L)   116   115   0   0   24   31   1.19   1.13  Effluent   PO 4   3 −   (mg/L)   51   27   0   0   8   8   1.14   1.09  The   number   of   nearest   neighbours   (k)   used   in   this   study   was  determined   by   calculating   the   input   weights   as   k   is   increased   from  1   to   500.   Weights   were   used   at   k   =   200,   where   the   results   have  stabilized,   as   shown   in   Fig.   5 .  2.5.   Artificial   neural   networks  Artificial   neural   networks   mimic   the   way   neurons   work   in   the  human   brain   to   perform   complex   operations.   The   ANNs   type   used  in   this   study,   feed-forward   neural   networks,   utilize   an   error   min-  imization   algorithm   to   tune   the   network   weights   ( Fernando   &  Shamseldin,   2009 ;   Sammut   &   Webb,   2016 ).   Well   designed   and  trained   neural   networks   can   achieve   outstanding   prediction   accu-  racies;   however,   this   comes   at   the   expense   of   long   training   time   as  the   error   minimization   functions   are   generally   slow   to   converge.  Additionally,   large   training   datasets   are   needed   to   reach   high   pre-  diction   accuracies   without   overfitting.   Neural   networks   can   also  overfit   if   the   inputs   are   not   well   selected   or   the   layers   architecture  is   not   well   designed   ( Lawrence   &   Giles,   20  0  0 ;   Ye   et   al.,   2020 ).  In   this   study,   Bayesian   Regularization   was   used   as   the   objec-  tive   function   for   error   minimization   using   a   linear   formulation   of  squared   errors   and   network   weights   ( Foresee   &   Hagan,   1997 ).   The  network   architectures   were   selected   by   training   all   ANN   combina-  tions   of   (1-3)   hidden   layers   and   (1-10)   hidden   nodes   in   each   layer.  This   approach   resulted   in   the   training   of   8880   neural   networks   for  the   8   outputs.   The   best   performing   network   selected   for   each   of  the   outputs   was   the   one   with   the   most   accurate   prediction   (lowest  error)   and   with   similar   training   and   test   performance.   These   condi-  tions   ensured   that   the   chosen   networks   did   not   overfit   or   underfit.  2.6.   Adaptive   neuro-fuzzy   inference   systems  The   adaptive   neuro-fuzzy   inference   systems   (ANFIS)   is   used   to  simulate   complex   processes   with   measurement   uncertainty.   It   is   a  universal   approximator   that   utilizes   logical   rules   to   reach   an   out-  put   through   human-like   reasoning   ( Jang,   1993 ).   In   ANFIS,   member-  ship   functions   are   used   to   map   numerical   inputs   to   fuzzy   sets.   A  learning   algorithm,   similar   to   the   back-propagation   algorithm,   is  used   to   minimize   the   errors   by   optimizing   the   ANFIS   parameters.  Each   of   the   outputs   in   this   study   was   predicted   using   a   separate  ANFIS   model.   The   clustering   method   used   was   Grid   Partitioning,   as  it   allows   for   choosing   the   desired   membership   functions.   Grid   par-  titioning,   however,   assigns   a   fuzzy   rule   for   each   input-membership  function   combination,   which   exponentially   increases   the   number  of   rules   and   the   computational   requirement   for   training   the   mod-  els.  2.7.   Support   vector   regression  Support   vector   regression   (SVR)   is   an   algorithm,   based   on   the  statistical   learning   theory,   that   uses   the   structural   risk   minimiza-  tion   (SRM)   method   to   minimize   the   modelling   error   and   maintain  low   model   complexity   ( Smola   &   Schölkopf,   2004 ;   Vapnik,   2000 ).  The   nonlinear   SVR   model   formula   is   shown   in   Eq.   (2)   for   an   input  vector   x ,   output   vector   y ,   and   N   number   of   samples.  y   =  N ∑  i = 1  w i   φ i   ( x  )   +   b   (2)  where   w i   is   a   weight   vector,   b   is   bias,   φ i   is   a   nonlinear   kernel  function   that   maps   the   training   data   to   a   higher   dimensional   fea-  ture   space,   making   it   possible   to   linearize   the   model   ( Smola   &  Schölkopf,   2004 ).   A   Gaussian   kernel   was   used   as   it   is   easier   to   tune  than   other   functions,   and   it   can   also   handle   complex   error   bound-  aries   ( Goyal   &   Ojha,   2011 ).  Three   hyperparameters   need   tuning   in   SVR:   the   kernel   scale  ( γ   ),   box   constraint   (C)   and   the   error   band   ( ε ).   The   kernel   scale   ( γ   )  determines   how   much   the   kernel   function   will   detect   variation   in  the   input   vectors.   It   is   inversely   proportional   to   the   sensitivity   of  the   kernel   function   to   input   variation.   The   SVR   model   can   underfit  if   the   kernel   function   is   not   sensitive   enough   to   detect   changes   in  inputs   and   can   overfit   if   the   kernel   function   was   too   sensitive   to  detect   the   smallest   variation   in   inputs.   The   box   constraint   (C)   is   a  regularization   factor   needed   by   the   SRM   to   control   the   penalty   on  large   prediction   residual   errors.   It   represents   the   trade-off between  the   training   error   and   model   complexity,   where   small   C   values  will   result   in   poor   predictions,   and   large   values   will   cause   overfit-  ting.   Finally,   the   error   band   represents   the   space   where   the   predic-  tions   can   be   made   around   the   actual   measured   values.   Tighter   er-  ror   bands   will   result   in   more   accurate   predictions   at   the   expense   of  the   model   complexity.   More   details   on   the   mathematical   formula-  tion   of   SVR   can   be   found   in   ( Awad   &   Khanna,   2015 ;   Cristianini   and  Shawe-Taylor,   20  0  0 ;   Smola   &   Schölkopf,   2004 ).  5
M.S.   Zaghloul,   O.T.   Iorhemen,   R.A.   Hamza   et   al.   Water   Research   189   (2021)   116657  -0.02 0 0.02 0.04 0.06 0.08 0.1 0   50   100   150   200  MLSS Inputs  -0.02 0 0.02 0.04 0.06 0.08 0.1 0   50   100   150   200  MLVSS Inputs  -0.02 0 0.02 0.04 0.06 0.08 0.1 0   50   100   150   200  SVI 5   Inputs  -0.02 0 0.02 0.04 0.06 0.08 0.1 0   50   100   150   200  SVI 30   Inputs  -0.02 0 0.02 0.04 0.06 0.08 0.1 0   50   100   150   200  Granule Size Inputs  -0.1 -0.05 0 0.05 0.1 0.15 0.2 0.25 0   50   100   150   200  Effluent COD Inputs  -0.02 0 0.02 0.04 0.06 0.08 0   50   100   150   200  Effluent NH   4   -N Inputs  -0.02 0 0.02 0.04 0.06 0.08 0.1 0.12 0   50   100   150   200  Effluent PO   43-   Inputs  Fig.   5.   Stability   of   input   scores   (y-axes)   with   varying   k   values   (x-axes).  3.   Results   and   Discussion  3.1.   Aerobic   Granular   Sludge   Performance  The   reactors   simulated   in   this   study   were   operated   for   data  collection   for   a   collective   of   475   days.   Periods   of   stable   oper-  ation   have   been   observed   along   with   some   disruptions   due   to  biomass   washout.   The   average   ( ±   standard   deviation)   influent   COD,  NH 4  +  -N,   and   PO 4  3 −   concentrations   in   the   reactors   are   3309 ± 1838,  130 ± 41,   and   48 ± 18   mg/L,   respectively.   The   systems   exhibited   sta-  ble   organics   and   nutrients   removal   throughout   the   duration   of   the  experiment,   with   an   average   COD,   NH 4  +  -N,   and   PO 4  3 −   removal   ef-  ficiencies   of   96 ± 8,   81 ± 18,   and   84 ± 18%,   respectively.   Aerobic   gran-  ular   sludge   has   been   proven   to   have   consistent   good   removal   of   or-  ganics   and   nutrients   ( de   Kreuk   et   al.,   2005 ;   Iorhemen   et   al.,   2020 ;  Nancharaiah   &   Reddy,   2018 ).   The   stratification   of   aerobic,   anoxic,  and   anaerobic   microbial   communities   has   also   been   observed,   re-  sulting   in   better   nitrogen   and   phosphorus   removal   ( Wang   et   al.,  2008 ;   Yilmaz   et   al.,   2008 ).  The   average   MLSS   and   MLVSS   concentrations   were   7888 ± 5158  and   6284 ± 3810mg/L,   respectively.   The   average   MLSS/MLVSS   ratio  was   80%,   which   is   a   typical   value   in   aerobic   treatment   reactors.  The   average   SVI 5   and   SVI 30   were   114 ± 63,   and   73 ± 34   mL/g,   re-  spectively,   demonstrating   the   fast   settling   of   the   granules.   Granules  are   considered   to   have   good   settling   properties   when   SVI 30   is   be-  low   100   mL/mg   ( Hamza   et   al.,   2018 ;   Liu   et   al.,   2007 ).   The   average  ratio   of   granulation   in   AGS   reactors,   calculated   by   the   SVI 30  /SVI 5  ( Hamza   et   al.,   2018 ),   was   64%,   and   the   average   granule   diame-  ter   was   445 ± 206   μm,   which   showed   that   the   biomass   was   mostly  granular.   The   presence   of   some   floccular   biomass   and   fluctuation  in   settling   properties   were   expected   due   to   the   variation   in   F/M  ratio   (2 ± 1)   ( Hamza   et   al.,   2018 ).  6
M.S.   Zaghloul,   O.T.   Iorhemen,   R.A.   Hamza   et   al.   Water   Research   189   (2021)   116657  Table   3  Multicollinearity   reduction.  Model  stage  Max.   VIF   before  reduction  Max.   VIF   after  reduction  Initial   number  of   inputs  Final   number  of   inputs  Number   of  inputs   removed  Stage   2   990.55   4.63   13   9   4  Stage   3   1078.9   2.49   15   10   5  Stage   4   1132.1   3.11   18   10   8  Stage   5   1141.9   4.28   19   12   7  Table   4  Algorithms   in   which   each   of   the   inputs   was   used   for   each   output.  Parameter  Outputs  MLSS   MLVSS   SVI 5   SVI 30   Granule   Size   Effluent   COD   Effluent   NH 4   -N   Effluent   PO 4   3 −  Influent   NH 4   -N   (mg/L)   N   -   S   -   A   N   -   S   -   A   N   -   S   -   A   N   -   S   -   A   N   -   S   -   A   N   -   S   -   A   N   -   S   -   A   N   -   S   -   A  Influent   PO 4   3 −   (mg/L)   N   -   S   -   A   N   -   S   -   A   N   -   S   N   -   S   N   -   S   N   -   S   -   A   N   -   S   -   A   N   -   S   -   A  Volume   (L)   N   -   S   -   A   N   -   S   N   -   S   N   -   S   -   A   N   -   S   -   A  Influent   pH   N   -   S   -   A   N   -   S   N   -   S   N   -   S   N   -   S   N   -   S   N   -   S  OLR   (kg   COD/m 3   )   N   -   S   -   A   N   -   S   -   A  HRT   (h)   N   -   S   -   A   N   -   S   -   A   N   -   S   -   A   N   -   S   -   A   N   -   S   -   A   N   -   S   -   A   N   -   S   -   A   N   -   S  Superficial   Air   Vel.   (cm/s)   A   N   -   S   -   A   N   -   S   -   A   N   -   S   -   A   N   -   S   -   A   N   -   S   -   A  Temperature   ( ° C)   N   -   S   N   -   S   N   -   S   N   -   S   -   A   N   -   S   -   A   N   -   S   -   A   N   -   S  Settling   time   (min)   S   N   -   S   -   A   N   -   S   -   A   N   -   S   N   -   S   -   A   N   -   S  MLVSS   (mg/L)   N   -   S   -   A   N   -   S   -   A   N   -   S   N   -   S   -   A   N   -   S   -   A  SVI 5   (mL/g)   N   -   S   -   A  SVI 30   (mL/g)   N   -   S   -   A  Granule   Size   ( μ m)   N   -   S   -   A   N   N   -   S   -   A  F/M   Ratio   N   -   S   N   N   -   S  3.2.   Feature   Selection  The   ANN,   SVR   and   ANFIS   models   that   were   used   to   predict  outputs   1,   2   and   3   ( Fig.   3 )   were   developed   using   the   operation  and   performance   dataset,   which   was   collected   from   the   laboratory  ( Table   2 ).   Feature   selection   was   necessary   to   overcome   the   mul-  ticollinearity   between   different   parameters   and   remove   the   inputs  that   adversely   affect   the   model   performance.   The   feature   selection  methods   used   in   this   study   were   able   to   reduce   the   level   of   mul-  ticollinearity   and   identify   the   most   effective   parameters   for   each  output,   which   resulted   in   the   elimination   of   some   parameters.   Cal-  culating   the   VIF   for   the   inputs   of   each   stage   resulted   in   the   reduc-  tion   of   inputs   by   4,   5,   8,   and   7   for   stages   2,   3,   4,   and   5,   respectively.  The   results   of   the   multicollinearity   reduction   are   shown   in   Table   3 .  The   level   of   multicollinearity   is   accepted   once   the   maximum   VIF  is   below   5.   The   data   collection   plan   was   quite   thorough   in   the   se-  lection   of   parameters   to   measure.   This   resulted   in   a   high   level   of  multicollinearity   in   the   initial   dataset   due   to   the   close   relationships  between   parameters,   such   as   the   OLR-COD,   or   the   flowrate-reactor  volume-HRT   ( Price,   1998 ).  Further   dimensionality   reduction   was   applied   using   the   RReli-  efF   algorithm   to   rank   the   inputs   for   each   output.   Unlike   the   VIF  test   that   was   input   dependent,   the   RReliefF   weights   depended   on  the   relationship   between   the   inputs   and   outputs,   which   resulted  in   different   input   weights   for   each   of   the   outputs   even   within   the  same   stage.   Table   4   shows   the   final   inputs   used   for   the   ANN,   SVR,  and   ANFIS   models.   In   Table   4 ,   the   ANN   was   denoted   by   “N”,   SVR  was   denoted   by   “S”,   and   ANFIS   was   denoted   by   “A”.   Table   4   shows,  for   each   output,   the   models   in   which   each   of   the   predictors   was  used,   for   example,   the   influent   NH 4  -N,   influent   PO 4  3 − ,   OLR   and  HRT   were   used   as   inputs   for   the   MLVSS   ANFIS   model.   The   rank-  ing   done   using   the   RReliefF   algorithm   was   used   for   the   three   mod-  elling   algorithms.   Selected   inputs   were   chosen   from   the   ranked   list  and   noting   the   model   performance   until   the   model   stopped   im-  proving   or   was   unable   to   complete   the   training   due   to   computa-  tional   limitation   (in   ANFIS   models).  The   ANFIS   model   was   restricted   by   the   number   of   inputs   to   be  used   as   is   was   found   that   adding   more   inputs   would   significantly  increase   the   required   training   time   and   CPU   usage.   ANFIS   was   lim-  ited   to   a   maximum   of   six   inputs   selected   according   to   the   RReliefF  ranking,   except   for   the   MLVSS,   where   the   best   performance   was  achieved   with   four   inputs   and   the   effluent   ammonia   where   seven  inputs   had   to   be   used   to   achieve   acceptable   performance.  Feature   selection   was   found   to   be   the   most   important   step   in  the   development,   as   it   has   improved   the   performance   of   the   ANN,  SVR,   and   ANFIS   models   by   raising   the   overall   evaluation   average  R 2   from   93%,   85%,   and   83%   to   94.2%,   92.4%   and   85.6%   respectively  using   the   same   data   and   model   structure.  3.3.   Model   Development  The   ANN   model   was   trained   using   the   selected   inputs   in  Table   4 .   The   network   architectures   for   each   ANN   model   are   shown  in   Table   5 .   All   ANN   models   had   three   hidden   layers   with   differ-  ent   combinations   of   hidden   nodes.   Table   5   also   shows   the   tuned  SVR   hyperparameters.   There   is   a   large   variation   in   the   values   of  C,   γ   and   ε   between   the   models.   The   available   literature   explains  the   individual   effect   of   each   of   the   hyperparameters   on   the   per-  formance   of   the   trained   SVR   models   and   the   risk   of   overfitting.  However,   the   hyperparameters   have   a   combined   effect   on   the   per-  formance.   The   values   of   C,   γ   and   ε ,   were   optimized   within   the  SVR   training   process   using   Bayesian   optimization   to   minimize   5-  fold   cross-validation   error.   The   optimization   of   the   hyperparame-  ters   results   in   the   best   possible   prediction   accuracy   without   signif-  icant   overfitting.   Finally,   the   ANFIS   models   were   all   assigned   two  input   membership   functions.   It   was   difficult   to   increase   the   num-  ber   of   membership   functions   due   to   computational   limitations   that  resulted   in   failing   to   train   the   models.   Different   membership   func-  tions   were   tested,   and   the   best-performing   ones   were   chosen   for  the   final   model.   Triangular-type   membership   functions   were   used  for   the   MLSS,   MLVSS,   SVI 30   and   effluent   NH 4  -N   ( Eq.   3 ).  y   =  ⎧  ⎪ ⎪ ⎪ ⎪ ⎪ ⎨  ⎪ ⎪ ⎪ ⎪ ⎪ ⎩  0 ,   x   ≤   a  x   −   a  b   −   a   ,   a   ≤   x   ≤   b  c   −   x  c   −   b   ,   b   ≤   x   ≤   c  0 ,   x   ≥   c  (3)  7
M.S.   Zaghloul,   O.T.   Iorhemen,   R.A.   Hamza   et   al.   Water   Research   189   (2021)   116657  Table   5  ANN   architectures,   SVR   hyperparameters   and   ANFIS   membership   functions.  Output  ANN  Architectures  SVR   Hyperparameters  ANFIS   Membership   Function  C   γ   ε  MLSS   (mg/L)   6-4-3   1.763   1.8302   1.33E-04   Triangular  MLVSS   (mg/L)   5-4-9   244.46   8.6594   0.0004098   Triangular  SVI 5   (mL/g)   6-3-1   49.959   4.1236   0.0001425   Gaussian   Combination  SVI 30   (mL/g)   2-7-4   0.59194   5.2062   0.013026   Triangular  Granule   Size   ( μ m)   2-9-8   121.55   1.4949   0.0003605   Gaussian   Combination  Effluent   COD   (mg/L)   7-1-1   7.9007   2.7712   7.226E-06   Gaussian   Combination  Effluent   NH 4   -N   (mg/L)   6-6-1   1.2535   1.0669   0.0007429   Triangular  Effluent   PO 4   3 −   (mg/L)   5-1-1   17.613   2.87   0.0002448   Gaussian   Combination  Table   6  E-ANN   architectures,   E-SVR   hyperparameters   and   E-ANFIS   membership   functions.  Output  E-ANN  Architectures  E-SVR   Hyperparameters  E-ANFIS   Membership   Function  C   γ   ε  MLSS   (mg/L)   1   274.69   3.1267   0.0001948   Gaussian   Combination  MLVSS   (mg/L)   1   969.84   16.172   0.0006375   Gaussian   Combination  SVI 5   (mL/g)   1   932.21   222.88   0.0005993   Gaussian   Combination  SVI 30   (mL/g)   1   286.84   38.591   0.0071388   Gaussian   Combination  Granule   Size   ( μ m)   1   892.45   377.84   0.0002951   Gaussian   Combination  Effluent   COD   (mg/L)   1   998.2   115.86   0.0001844   Gaussian   Combination  Effluent   NH 4   -N   (mg/L)   1   886.38   329.18   0.0002088   Gaussian   Combination  Effluent   PO 4   3 −   (mg/L)   1   942.59   231.49   0.0012618   Gaussian   Combination  where   a,   b   and   c   are   constants   determined   through   the   ANFIS  training.   The   rest   of   the   ANFIS   models   used   Gaussian   Combination  membership   functions   ( Eq.   4 ).  y   =   e   − ( x − μ   ) 2  2 σ   2   (4)  where   σ   is   the   standard   deviation,   and   μ is   the   mean   of   the   train-  ing   data.   The   average   training   performance   of   the   ANN   model   for  all   outputs   was   96%,   0.03,   and   3.3%   for   R 2  ,   nRMSE   and   sMAPE,  respectively.   The   average   training   performance   of   the   SVR   model  for   all   outputs   was   95.8%,   0.026,   and   1.9%   for   R 2  ,   nRMSE   and  sMAPE,   respectively.   The   average   training   performance   of   the   AN-  FIS   model   for   all   outputs   was   92.5%,   0.047,   and   4.6%   for   R 2  ,   nRMSE  and   sMAPE,   respectively.   The   overall   performance   of   SVR   was   bet-  ter   than   ANN   in   terms   of   nRMSE   and   sMAPE.   The   ANFIS   model   was  considerably   less   accurate   than   the   ANN   and   SVR,   which   can   be   at-  tributed   to   the   computational   limitation   on   the   number   of   inputs  and   membership   functions   that   were   used.  The   outputs   of   the   ANN,   SVR   and   ANFIS   models   were   used   as  inputs   to   five   ensemble   alternatives:   E-ANN,   E-SVR,   E-ANFIS,   E-AVG  and   E-WAVG.   The   E-AVG   was   the   arithmetic   mean   of   the   three   in-  puts,   which   resulted   in   an   overall   average   training   performance  of   97.3%,   0.027,   and   2.8%   for   R 2  ,   nRMSE   and   sMAPE,   respectively.  E-WAVG   was   a   weighted   average   of   the   three   inputs   using   the  training   R 2   of   the   ANN,   SVR   and   ANFIS   for   each   output   as   rel-  ative   weights.   This   approach   had   the   advantage   of   favouring   the  more   accurate   inputs   which   provided   an   improvement   over   E-AVG  when   there   was   a   large   difference   in   accuracy   between   the   ANN,  SVR   and   ANFIS.   The   overall   average   performance   of   the   E-WAVG  was   97.8%,   0.024,   and   2.4%   for   R 2  ,   nRMSE   and   sMAPE,   respectively.  The   E-ANN,   E-SVR,   and   E-ANFIS   are   machine   learning-based   en-  sembles   where   the   ANN,   SVR   and   ANFIS   outputs   were   used   as   in-  puts.   Table   6   shows   the   architecture,   hyperparameters   and   mem-  bership   functions   of   the   E-ANN,   E-SVR,   and   E-ANFIS,   respectively.  These   algorithms   were   much   simpler   in   their   development   as   they  were   intended   to   use   three   versions   of   the   true   output   to   make  the   predictions.   Also,   the   number   of   inputs   was   much   less   than  the   original   three   models.   Maintaining   a   simple   model   was   essen-  tial   to   ensure   that   overfitting   was   minimal,   considering   the   small  number   of   inputs   (three)   and   that   the   inputs   are   variants   of   the  same   parameters   that   are   already   close   to   the   desired   solution.   All  neural   networks   had   one   hidden   layer   with   a   single   neuron   provid-  ing   a   training   performance   of   98.7%,   0.016,   and   1.8%   for   R 2  ,   nRMSE  and   sMAPE   respectively.   The   E-SVR   hyperparameters   provide   in-  sight   into   the   performance   of   the   algorithm,   where   large   C   values  indicate   larger   penalties   on   errors   in   all   outputs.   However,   the   γ  values   were   also   much   higher   than   the   SVR   model,   indicating   that  the   kernel   function   is   not   as   sensitive   to   the   variation   in   the   in-  puts.   The   overall   average   training   performance   of   the   E-SVR   was  98.7%,   0.016,   and   1.6%   for   R 2  ,   nRMSE   and   sMAPE,   respectively.   The  E-ANFIS   models   had   2   Gaussian   Combination   membership   func-  tions   with   an   overall   training   performance   of   94.3%,   0.031,   and   1.9%  for   R 2  ,   nRMSE   and   sMAPE,   respectively.  3.4.   Model   Performance  The   developed   algorithms   in   this   study   (ANN,   SVR,   ANFIS,   E-  ANN,   E-SVR,   E- ANFIS,   E- AVG,   E-WAVG)   were   all   validated   using   the  evaluation   dataset   that   was   isolated   before   developing   the   models.  Table   7   shows   the   overall   evaluation   performance   averaged   for   all  outputs   for   each   algorithm.   It   was   found   that   the   E-ANN   provided  the   best   performance   in   terms   of   R 2  ,   nRMSE,   and   sMAPE.   The   E-  SVR   and   E-WAVG   provided   a   close   performance   to   the   E-ANN,   but  the   E-ANFIS   was   not   able   to   reach   the   same   level   of   performance.  Although   E-ANN   outperformed   the   other   ensemble   algorithm   in  the   overall   performance,   the   E-WAVG   was   able   to   provide   a   some-  what   better   prediction   accuracy   for   the   granule   size   with   an   R 2  of   89%   as   opposed   to   the   E-ANN   with   an   R 2   of   85%.   The   ensem-  ble   models   did   not   provide   an   improvement   over   the   ANN   for   the  prediction   of   the   effluent   COD,   where   the   ANN   provided   an   R 2   of  99.65%   as   opposed   to   the   99.3%   R 2   of   the   E-ANN.   The   best   per-  forming   models   for   each   of   the   outputs   were   selected   for   the   final  model   as   shown   in   Table   8 .   Fig.   6   shows   the   diagonal   plots   of   the  final   selected   models.  After   using   the   best   performing   ensemble   algorithms,   the   fi-  nal   model   improved   the   overall   prediction   accuracy   over   the   ANN  model,   the   best   performing   single   algorithm,   by   raising   the   overall  average   R 2   from   94.2%   to   95.2%   and   reducing   the   overall   average  nRMSE   from   0.037   to   0.032,   and   the   overall   average   sMAPE   from  8
M.S.   Zaghloul,   O.T.   Iorhemen,   R.A.   Hamza   et   al.   Water   Research   189   (2021)   116657  Fig.   6.   Diagonal   plots   of   the   final   model   predictions   vs.   target   measured   values   using   the   evaluation   dataset.  9
M.S.   Zaghloul,   O.T.   Iorhemen,   R.A.   Hamza   et   al.   Water   Research   189   (2021)   116657  Table   7  Overall   average   evaluation   performance.  Metric   ANN   SVR   ANFIS   E-ANN   E-SVR   E-ANFIS   E-AVG   E-WAVG  R 2   94.2%   92.4%   85.6%   95.2%   94.5%   80.3%   94.6%   95%  nRMSE   0.037   0.043   0.062   0.034   0.036   0.081   0.037   0.035  sMAPE   4.2%   4.6%   7.7%   3.8%   4%   6.4%   4.5%   4.2%  Table   8  Final   model   performance   using   the   best   performing   algorithms.  Output  Chosen  Algorithm  R 2   (%)   nRMSE   sMAPE   (%)  Training   Evaluation   Training   Evaluation   Training   Evaluation  MLSS   (mg/L)   E-NN   97.80%   96.11%   0.031   0.036   3.06%   4.05%  MLVSS   (mg/L)   E-NN   97.58%   94.30%   0.031   0.043   2.91%   4.56%  SVI 5   (mL/g)   E-NN   98.53%   95.89%   0.017   0.028   2.29%   3.16%  SVI 30   (mL/g)   E-NN   95.81%   92.19%   0.025   0.030   2.93%   3.49%  Granule   Size   ( μ m)   E-WAVG   97.06%   88.75%   0.038   0.073   2.54%   3.78%  Effluent   COD   (mg/L)   NN   99.65%   99.65%   0.009   0.008   3.06%   5.63%  Effluent   NH 4   -N   (mg/L)   E-NN   99.89%   99.53%   0.008   0.021   0.92%   1.98%  Effluent   PO 4   3 −   (mg/L)   E-NN   99.72%   98.96%   0.010   0.018   1.85%   2.88%  Table   9  Comparison   between   the   dataset   size   and   prediction   R 2   (%)   of   this   study   and   other   machine   learning   models   for   AGS   and   CAS.  Study   Algorithm   Model  Dataset  Size  (days)  Biomass   Effluent  MLSS   MLVSS   SVI 5   SVI 30   Granule   Size   COD   NH 4   -N   TKN   TN   PO 4   3 −  This   study   Ensemble   AGS   475   96.1   94.3   95.9   92.2   88.75   99.7   99.5   -   -   99.0  ( Zaghloul   et   al.,  2020 )  ANFIS   AGS   2920   87.5   86.6   96.3   95.6   81.5   98.5   99.6   -   -   86.7  SVR   99.9   99.9   99.9   99.8   99.8   99.9   99.9   -   -   99.7  ( Zaghloul   et   al.,   2018 )   ANN   AGS   2886   99.5   99.6   99.6   99.0   99.2   100.0   99.9   -   -   99.9  ( Gong   et   al.,   2018 )   ANN   AGS   205   (136) ∗   -   -   -   -   -   90.0   -   -   81.0   -  ( Mahmod   &   Wahab,   2017 )   ANN   AGS   21   -   -   -   -   -   91.2   -   -   -   -  ( Manu  &  Thalla,   2017 )  ANFIS   CAS   88   -   -   -   -   -   -   -   72.0   -   -  SVR   -   -   -   -   -   -   -   82.5   -   -  ( Guo   et   al.,  2015 )  ANN   CAS   305   -   -   -   -   -   -   -   -   47.0   -  SVR   -   -   -   -   -   -   -   -   46.0   -  ∗   COD   dataset   was   205   days,   TN   dataset   was   136   days.  4.2%   to   3.7%.   The   most   significant   improvement   was   observed   in  the   granule   size,   where   the   R 2   was   increased   from   81%   to   88.2%.  It   was   found   that   even   though   the   E-SVR   was   close   to   the   E-  ANN   in   terms   of   prediction   accuracy   of   the   evaluation   data,   it   suf-  fered   from   a   slightly   higher   level   of   overfitting   in   some   of   the   out-  puts   where   the   difference   between   the   training   and   evaluation   pre-  dictions   was   larger   than   that   of   E-ANN.   The   E-ANFIS   did   not   pro-  vide   predictions   as   accurately   as   the   other   ensembles,   as   there   was  not   enough   distinction   in   the   input   parameters   for   the   ANFIS   to   be  able   to   develop   a   reliable   rule-base.  Table   9   compares   the   model   developed   in   this   study   to   other  machine   learning   models   in   the   literature   using   the   prediction   R 2  of   the   validation   datasets   as   a   performance   indicator.   The   com-  parison   shows   that   this   study   can   achieve   prediction   accuracies  that   are   similar   to   those   made   by   AGS   machine   learning   mod-  els   with   much   larger   datasets   ( Zaghloul   et   al.,   2020 ).   It   can   also  be   observed   that   the   performance   of   the   model   developed   in   this  study   achieves   prediction   accuracies   that   are   higher   than   AGS  models   that   were   developed   with   small   datasets   ( Gong   et   al.,  2018 ;   Mahmod   &   Wahab,   2017 ).   Other   CAS   models   with   small  datasets   resulted   in   predictions   that   are   consistent   with   AGS   mod-  els   ( El-Din   et   al.,   2004 ;   Manu   &   Thalla,   2017 ).   The   small   size   of  test   datasets   can   result   in   less   reliable   models   that   do   not   pro-  vide   consistent   results,   which   is   demonstrated   in   the   results   of  Mahmod   and   Wahab   (2017) ,   where   the   training   and   testing   R 2  were   78%   and   91.17%,   respectively   ( Mahmod   &   Wahab,   2017 ).   SVR  and   ANNs   were   found   to   perform   at   the   same   level   of   accuracy  in   other   CAS   and   AGS   models,   which   is   consistent   with   the   mod-  els   developed   in   this   study   ( Gong   et   al.,   2018 ;   Guo   et   al.,   2015 ;  Mahmod   &   Wahab,   2017 ;   Seshan   et   al.,   2014 ).  4.   Multi-Stage   Model   Structure  AGS   machine   learning   models   in   the   literature   are   all   single-  stage   models   where   a   group   of   inputs   is   used   to   predict   the   fi-  nal   effluent   quality   parameters   without   considering   the   process   se-  quence   ( Gong   et   al.,   2018 ;   Mahmod   &   Wahab,   2017 ).   Two-stage  models   were   designed   to   improve   the   model   structure   with   suc-  cess   ( Zaghloul   et   al.,   2020 ).   The   multi-stage   model   structure   makes  the   model   developed   in   this   study   more   versatile   than   other   ma-  chine   learning   models   as   it   considers   the   effect   of   influent   char-  acteristics   on   the   biomass   properties   and   the   consequent   effect   on  the   effluent   quality.   The   multi-stage   model   structure   also   provides  the   ability   to   identify   the   source   of   predicted   effluent   quality   is-  sues,   where   the   different   biomass   properties   that   were   predicted  at   the   same   instance   can   be   analyzed.   This   mitigates   the   disadvan-  tage   of   the   application   of   black-box   models   that   can   be   difficult   to  use   for   process   interpretation   ( Newhart   et   al.,   2019 ).  5.   Failure   prediction  The   model   developed   in   this   study   can   accurately   predict   the  performance   of   AGS   reactors   under   varying   operational   and   in-  fluent   conditions.   The   model   provides   a   tool   that   can   be   used   to  forecast   the   reactor   behaviour   during   operation,   which   will   guide  the   operators   on   experimental   design.   Fig.   7   shows   the   predictions  made   for   a   portion   of   the   evaluation   dataset   (chronologically   or-  dered   and   obtained   from   the   same   reactor)   plotted   with   failure  thresholds.   Operators   can   utilize   such   figures   to   identify   sources  of   process   failures   and   potential   causes.  10
M.S.   Zaghloul,   O.T.   Iorhemen,   R.A.   Hamza   et   al.   Water   Research   189   (2021)   116657  Fig.   7.   Measured   vs   predicted   values   with   the   local   treated   effluent   regulations.  The   local   treated   effluent   standards   were   set   as   thresholds   for  this   study.   Maximum   effluent   COD,   NH 4  -N,   and   PO 4  3 −   were   set   to  20   mg/L,   10   mg/L,   and   0.5   mg/L,   respectively.   The   threshold   for   the  granule   size   was   set   to   200   μm,   below   which   the   biomass   would  be   considered   floccular   ( Liu   et   al.,   2010 ),   which   indicates   either  structural   integrity   failure   of   the   granule   or   failure   to   achieve   a  state   of   granulation.   The   MLSS   threshold   was   chosen   for   this   study  to   be   40  0  0   mg/L.   The   MLSS   dropping   below   the   threshold   would  indicate   a   washout   of   the   biomass   due   to   poor   settling.   The   settling  properties   can   also   be   predicted   by   the   SVI   values.   Additionally,   the  SVI 30  /SVI 5   indicates   the   percentage   or   granulation   inside   the   reac-  tor,   as   defined   by   Kocaturk   and   Erguder   (2016) .   The   threshold   for  the   SVI 30  /SVI 5   was   set   to   50%   for   this   study.  It   can   be   observed   that   a   failure   to   remove   NH 4  -N   has   occurred  between   samples   218   and   232,   where   the   effluent   concentration  reached   28   mg/L.   The   MLSS   plot   shows   a   rapid   decline   in   the   MLSS  concentration,   which   entailed   a   loss   of   the   slow-growing   nitrifying  bacteria;   thus,   the   delayed   effect   of   poor   NH 4  -N   removal   while   the  biomass   recovered.   Further   analysis   of   the   results   shows   that   there  was   a   drop   in   the   granule   size   and   the   granulation   ratio   inside   the  reactor,   indicating   that   a   partial   washout   has   occurred,   followed   by  a   rapid   growth   of   heterotrophic   biomass   in   floccular   form   due   to  the   abundance   of   organics   (F/M   ratio   was   disturbed   due   to   the   loss  of   biomass).  The   influent   COD   was   reduced   from   around   70  0  0   mg/L   to   4500  mg/L   after   the   biomass   washout   instance.   This   improved   the   ob-  served   COD   removal   efficiency   as   the   new   heterotrophic   growth  was   able   to   handle   the   influent   organics.   The   effluent   COD   concen-  tration   was   above   the   allowed   threshold   as   the   reactor   was   being  operated   to   treat   high   organic   content   wastewater,   where   the   ef-  fluent   wastewater   was   to   be   polished   before   disposal.   The   aerobic  biological   process,   although   successful   in   removing   most   of   the   or-  ganic   load,   was   unable   to   bring   the   COD   concentrations   below   the  required   limits   ( Hamza   et   al.,   2018 ).  6.   Conclusion  A   machine   learning   model   was   developed   for   AGS   reactors  using   a   combination   of   neural   networks,   support   vector   regres-  sion   and   adaptive   neuro-fuzzy   inference   systems.   Feature   selec-  tion   methods   were   applied,   and   a   five-stage   model   structure   was  adopted.   This   study   shows   that   proper   feature   selection   and   com-  bining   multiple   machine   learning   algorithms   in   an   ensemble   can  improve   the   performance   of   data-driven   models   when   the   avail-  able   dataset   is   small.   The   two   feature   selection   methods   were   ap-  plied   to   reduce   the   dimensionality   of   the   regression   problem   and  reduce   the   multicollinearity   of   the   input   data.   Combining   multi-  ple   algorithms   using   simple   neural   networks   or   weighted   average  11
M.S.   Zaghloul,   O.T.   Iorhemen,   R.A.   Hamza   et   al.   Water   Research   189   (2021)   116657  ensembles   reduced   the   levels   of   over   and   under-fitting   of   the   indi-  vidual   algorithms.   The   modular   nature   of   the   model   structure   al-  lowed   the   use   of   best   performing   models,   out   of   the   eight   alterna-  tives,   for   each   output.   The   model   developed   in   this   study   was   able  to   predict   the   behaviour   of   AGS   reactors   and   provide   insight   into  the   process   by   explaining   the   causes   of   predicted   failures.  Declaration   of   Competing   Interest  None.  Acknowledgements  The   authors   would   like   to   acknowledge   the   National   Science  and   Engineering   Research   Council   of   Canada   for   funding   this   re-  search.  References  Alin,   A.,   2010.   Multicollinearity.   Wiley   Interdisciplinary   Reviews.   Computational  Statistics   2   (3),   370–374.   doi: 10.1002/wics.84 .  Awad,   M. ,   Khanna,   R. ,   2015.   Support   vector   regression.   In   Efficient   Learning   Ma-  chines.   Springer,   pp.   67–80 .  Baeten,   J.E.,   Batstone,   D.J.,   Schraa,   O.J.,   van   Loosdrecht,   M.C.M.,   Volcke,   E.I.P.,   2019.  Modelling   anaerobic,   aerobic   and   partial   nitritation-anammox   granular   sludge  reactors   -   A   review.   Water   Research   149,   322–341.   doi: 10.1016/j.watres.2018.11.  026 .  Baeten,   J.E.,   van   Loosdrecht,   M.C.M.,   Volcke,   E.I.P.,   2018.   Modelling   aerobic   granu-  lar   sludge   reactors   through   apparent   half-saturation   coefficients.   Water   Research  146,   134–145.   doi: 10.1016/j.watres.2018.09.025 .  Corominas,   L.,   Garrido-Baserba,   M.,   Villez,   K.,   Olsson,   G.,   Cortés,   U.,   Poch,   M.,   2018.  Transforming   data   into   knowledge   for   improved   wastewater   treatment   opera-  tion:   A   critical   review   of   techniques.   Environmental   Modelling   &   Software   106,  89–103.   doi: 10.1016/j.envsoft.2017.11.023 .  Cristianini,   N. ,   Shawe-Taylor,   J. ,   20  0  0.   An   introduction   to   support   vector   machines  and   other   kernel-based   learning   methods.   Cambridge   university   press .  Cui,   F.,   Kim,   M.,   Lee,   W.,   Park,   C.,   Kim,   M.,   2020.   Pseudo-analytical   solutions   for  multi-species   biofilm   model   of   aerobic   granular   sludge.   Environmental   Technol-  ogy   (United   Kingdom)   (0)   1–11.   doi: 10.1080/09593330.2020.1733673 ,   0.  de   Kreuk,   M.K.,   Heijnen,   J.J.,   van   Loosdrecht,   M.C.M.,   2005.   Simultaneous   COD,   ni-  trogen,   and   phosphate   removal   by   aerobic   granular   sludge.   Biotechnology   and  Bioengineering   90   (6),   761–769.   doi: 10.1002/bit.20470 .  El-Din,   A.G.,   Smith,   D.W.,   El-Din,   M.G.,   2004.   Application   of   artificial   neural   net-  works   in   wastewater   treatment.   Journal   of   Environmental   Engineering   and   Sci-  ence   3   (1),   S81–S95.   doi: 10.1139/s03-067 .  Fernando,   D.A.K.,   Shamseldin,   A.Y.,   2009.   Investigation   of   Internal   Functioning   of   the  Radial-Basis-Function   Neural   Network   River   Flow   Forecasting   Models.   Journal   of  Hydrologic   Engineering   14   (3),   286–292.   doi: 10.1061/(ASCE)1084-0699(2009)14 .  Foresee,   F.D.,   Hagan,   M.T.,   1997.   Gauss-Newton   approximation   to   Bayesian  learning.   In:   Proceedings   of   International   Conference   on   Neural   Networks  ({ICNN}{ \ textquotesingle}97),   3,   pp.   1930–1935.   doi: 10.1109/icnn.1997.614194 .  Franca,   R.D.G.,   Pinheiro,   H.M.,   van   Loosdrecht,   M.C.M.,   Lourenço,   N.D.,   2018.   Stability  of   aerobic   granules   during   long-term   bioreactor   operation.   Biotechnology   Ad-  vances   36   (1),   228–246.   doi: 10.1016/j.biotechadv.2017.11.005 .  Gong,   H.,   Pishgar,   R.,   Tay,   J.H.,   2018.   Artificial   neural   network   modelling   for   or-  ganic   and   total   nitrogen   removal   of   aerobic   granulation   under   steady-state   con-  dition.   Environmental   Technology   40   (24),   3124–3139.   doi: 10.1080/09593330.  2018.1466920 .  Goyal,   M.K.,   Ojha,   C.S.P.,   2011.   Estimation   of   Scour   Downstream   of   a   Ski-Jump   Bucket  Using   Support   Vector   and   M5   Model   Tree.   Water   Resources   Management   25   (9),  2177–2195.   doi: 10.1007/s11269-011-9801-6 .  Guo,   H.,   Jeong,   K.,   Lim,   J.,   Jo,   J.,   Kim,   Y.M.,   Park,   J.pyo,   Kim,   J.H.,   Cho,   K.H,   2015.  Prediction   of   effluent   concentration   in   a   wastewater   treatment   plant   using   ma-  chine   learning   models.   Journal   of   Environmental   Sciences   (China)   32,   90–101.  doi: 10.1016/j.jes.2015.01.007 .  Hamed,   M.M.,   Khalafallah,   M.G.,   Hassanien,   E.A.,   2004.   Prediction   of   wastewater  treatment   plant   performance   using   artificial   neural   networks.   Environmental  Modelling   &   Software   19   (10),   919–928.   doi: 10.1016/j.envsoft.2003.10.005 .  Hamza,   R.A.,   Iorhemen,   O.T.,   Zaghloul,   M.S.,   Tay,   J.H.,   2018.   Rapid   formation   and  characterization   of   aerobic   granules   in   pilot-scale   sequential   batch   reactor   for  high-strength   organic   wastewater   treatment.   Journal   of   Water   Process   Engineer-  ing   22.   doi: 10.1016/j.jwpe.2018.01.002 .  Hamza,   R.A.,   Sheng,   Z.,   Iorhemen,   O.T.,   Zaghloul,   M.S.,   Tay,   J.H,   2018.   Impact   of  food-to-microorganisms   ratio   on   the   stability   of   aerobic   granular   sludge   treating  high-strength   organic   wastewater.   Water   Research   147,   287–298.   doi: 10.1016/j.  watres.2018.09.061 .  He,   Q.,   Song,   J.,   Zhang,   W.,   Gao,   S.,   Wang,   H.,   Yu,   J.,   2020.   Enhanced   simultane-  ous   nitrification,   denitrification   and   phosphorus   removal   through   mixed   carbon  source   by   aerobic   granular   sludge.   Journal   of   Hazardous   Materials   382,   121043.  doi: 10.1016/j.jhazmat.2019.121043 ,   June   2019.  Iorhemen,   O.T.,   Zaghloul,   M.S.,   Hamza,   R.A.,   Tay,   J.H.,   2020.   Long-term   aerobic   granu-  lar   sludge   stability   through   anaerobic   slow   feeding,   fixed   feast-famine   period   ra-  tio,   and   fixed   SRT.   Journal   of   Environmental   Chemical   Engineering   8   (2),   103681.  doi: 10.1016/j.jece.2020.103681 .  Jang,   J.-S.R.,   1993.   ANFIS:   adaptive-network-based   fuzzy   inference   system.   IEEE  Transactions   on   Systems,   Man,   and   Cybernetics   23   (3),   665–685.   doi: 10.1109/  21.256541 .  Karamizadeh,   S.,   Abdullah,   S.M.,   Halimi,   M.,   Shayan,   J.,   javad   Rajabi,   M.,   2014,  September.   Advantage   and   drawback   of   support   vector   machine   functional-  ity.   2014   International   Conference   on   Computer,   Communications,   and   Control  Technology   (I4CT)   doi: 10.1109/i4ct.2014.6914146 .  Khan,   M.Z.,   Mondal,   P.K.,   Sabir,   S.,   2013.   Aerobic   granulation   for   wastewater   biore-  mediation:   A   review.   The   Canadian   Journal   of   Chemical   Engineering   91   (6),  1045–1058.   doi: 10.1002/cjce.21729 .  Kocaturk,   I.,   Erguder,   T.H.,   2016.   Influent   COD/TAN   ratio   affects   the   carbon   and   nitro-  gen   removal   efficiency   and   stability   of   aerobic   granules.   Ecological   Engineering  90,   12–24.   doi: 10.1016/j.ecoleng.2016.01.077 .  Lakshminarayan,   K.,   Harp,   S.A.,   Samad,   T.,   1999.   Imputation   of   missing   data  in   industrial   databases.   Applied   Intelligence   11   (3),   259–275.   doi: 10.1023/A:  1008334909089 .  Lawrence,   S.,   Giles,   C.L.,   20  0  0.   Overfitting   and   neural   networks:   Conjugate   gradient  and   backpropagation.   Proceedings   of   the   International   Joint   Conference   on   Neu-  ral   Networks   1,   114–119.   doi: 10.1109/ijcnn.20  0  0.857823 .  Lee,   M.W.,   Hong,   S.H.,   Choi,   H.,   Kim,   J.-H.H.,   Lee,   D.S.,   Park,   J.M.,   2008.   Real-time  remote   monitoring   of   small-scaled   biological   wastewater   treatment   plants   by  a   multivariate   statistical   process   control   and   neural   network-based   software  sensors.   Process   Biochemistry   43   (10),   1107–1113.   doi: 10.1016/j.procbio.2008.06.  002 .  Liang,   J.,   Wang,   Q.,   Li,   Q.X.,   Jiang,   L.,   Kong,   J.,   Ke,   M.,   Arslan,   M.,   Gamal   El-Din,   M.,  Chen,   C,   2020.   Aerobic   sludge   granulation   in   shale   gas   flowback   water   treat-  ment:   Assessment   of   the   bacterial   community   dynamics   and   modeling   of   biore-  actor   performance   using   artificial   neural   network.   Bioresource   Technology   313,  123687.   doi: 10.1016/j.biortech.2020.123687 ,   June.  Liu,   Y.Q.,   Kong,   Y.H.,   Zhang,   R.,   Zhang,   X.,   Wong,   F.S.,   Tay,   J.H.,   Zhu,   J.R.,   Jiang,   W.J.,  Liu,   W.T.,   2010.   Microbial   population   dynamics   of   granular   aerobic   sequencing  batch   reactors   during   start-up   and   steady   state   periods.   Water   Science   &   Tech-  nology   62   (6),   1281.   doi: 10.2166/wst.2010.408 .  Liu,   Yanzhu ,   Kong,   A.W.K. ,   Goh,   C.K. , 2017.   Deep   ordinal   regression   based   on   data  relationship   for   small   datasets.   In:   IJCAI   International   Joint   Conference   on   Arti-  ficial   Intelligence,   pp.   2372–2378 .  Liu,   Yu ,   Qin,   L. ,   Yang,   S.-F. ,   2007.   Microbial   granulation   technology   for   nutrient   re-  moval   from   wastewater.   Nova   Publishers .  Mahmod,   N.,   Wahab,   N.A.,   2017.   Dynamic   Modelling   of   Aerobic   Granular   Sludge   Ar-  tificial   Neural   Networks.   International   Journal   of   Electrical   and   Computer   Engi-  neering   7   (3),   1568.   doi: 10.11591/ijece.v7i3.pp1568-1573 .  Manu,   D.S.,   Thalla,   A.K.,   2017.   Artificial   intelligence   models   for   predicting   the   perfor-  mance   of   biological   wastewater   treatment   plant   in   the   removal   of   Kjeldahl   Ni-  trogen   from   wastewater.   Applied   Water   Science   7   (7),   3783–3791.   doi: 10.1007/  s13201-017-0526-4 .  Nancharaiah,   Y.V,   Reddy,   G.K.K.,   2018.   Aerobic   granular   sludge   technology:   Mecha-  nisms   of   granulation   and   biotechnological   applications.   Bioresource   Technology  247,   1128–1143.   doi: 10.1016/j.biortech.2017.09.131 .  Newhart,   K.B.,   Holloway,   R.W.,   Hering,   A.S.,   Cath,   T.Y.,   2019.   Data-driven   performance  analyses   of   wastewater   treatment   plants:   A   review.   Water   Research   157,   498– 513.   doi: 10.1016/j.watres.2019.03.030 .  Ni,   B.-J.,   Yu,   H.-Q.,   2010.   Mathematical   modeling   of   aerobic   granular   sludge:   A   re-  view.   Biotechnology   Advances   28   (6),   895–909.   doi: 10.1016/j.biotechadv.2010.08.  004 .  Price,   J.K. ,   1998.   Applied   math   for   wastewater   plant   operators.   CRC   Press .  Pronk,   M.,   de   Kreuk,   M.K.,   de   Bruin,   B.,   Kamminga,   P.,   Kleerebezem,   R.,   van   Loos-  drecht,   M.C.M.,   2015.   Full   scale   performance   of   the   aerobic   granular   sludge   pro-  cess   for   sewage   treatment.   Water   Research   84,   207–217.   doi: 10.1016/j.watres.  2015.07.011 .  Qin,   L.,   Tay,   J.H.,   Liu,   Y.,   2004.   Selection   pressure   is   a   driving   force   of   aerobic   gran-  ulation   in   sequencing   batch   reactors.   Process   Biochemistry   39   (5),   579–584.  doi: 10.1016/S0  032-9592(03)0  0125-0 .  Read,   C.B.,   Belsley,   D.A.,   1994.   Conditioning   Diagnostics:   Collinearity   and   Weak   Data  in   Regression.   Biometrics   50   (1),   314.   doi: 10.2307/2533229 .  Rice,   E.   W.,   Baird,   R.   B.,   &   Eaton,   A.   D.   (2017).   Standard   Methods   for   the   Examina-  tion   of   Water   and   Wastewater,   23rd   Edition   (23rd   ed.).   American   Public   Health  Association,   American   Water   Works   Association,   Water   Environment   Federation.  Robnik-Šikonja,   M. ,   Kononenko,   I. ,   1997.   An   adaptation   of   {R}elief   for   attribute   esti-  mation   in   regression.   In:   Machine   {L}earning:   {P}roceedings   of   the   {F}ourteenth  International   Conference,   5,   ICML’97,   pp.   296–304 .  Sammut,   C.,   &   Webb,   G.   I.   (2016).   Encyclopedia   of   Machine   Learning   and   Data   Min-  ing   (C.   Sammut   &   G.   I.   Webb   (eds.)).   Springer   {US}.   10.1007/978-1-4 899-76 87-1  Seshan,   H.,   Goyal,   M.K.,   Falk,   M.W.,   Wuertz,   S.,   2014.   Support   vector   regression  model   of   wastewater   bioreactor   performance   using   microbial   community   diver-  sity   indices:   Effect   of   stress   and   bioaugmentation.   Water   Research   53,   282–296.  doi: 10.1016/j.watres.2014.01.015 .  Shaikhina,   T.,   Khovanova,   N.A.,   2017.   Handling   limited   datasets   with   neural   net-  works   in   medical   applications:   A   small-data   approach.   Artificial   Intelligence   in  Medicine   75,   51–63.   doi: 10.1016/j.artmed.2016.12.003 .  Smola,   A.J.,   Schölkopf,   B.,   2004.   A   tutorial   on   support   vector   regression.   Statistics  and   Computing   14   (3),   199–222.   doi: 10.1023/b:stco.0  0  0  0  035301.4 954 9.88 .  12
M.S.   Zaghloul,   O.T.   Iorhemen,   R.A.   Hamza   et   al.   Water   Research   189   (2021)   116657  Stathakis,   D. ,   Savin,   I. ,   Networks,   F.N. ,   2006.   Neuro-Fuzzy   Modelling   For   Crop   Yield  Prediction.   The   International   Archives   of   the   Photogrammetry.   Remote   Sensing  and   Spatial   Information   Sciences   34,   8–11 .  Tay,   J.H.,   Liu,   Q.S.,   Liu,   Y.,   2002.   Characteristics   of   Aerobic   Granules   Grown   on   Glu-  cose   and   Acetate   in   Sequential   Aerobic   Sludge   Blanket   Reactors.   Environmental  Technology   23   (8),   931–936.   doi: 10.1080/09593332308618363 .  Urbanowicz,   R.J.,   Meeker,   M.,   La   Cava,   W.,   Olson,   R.S.,   Moore,   J.H.,   2018.   Relief-based  feature   selection:   Introduction   and   review.   Journal   of   Biomedical   Informatics   85  (June),   189–203.   doi: 10.1016/j.jbi.2018.07.014 .  Vapnik,   V.N.,   20  0  0.   The   Nature   of   Statistical   Learning   Theory.   Springer,   New   York  doi: 10.1007/978-  1-  4757-  3264-  1 .  Wang,   J.,   Wang,   X.,   Zhao,   Z.,   Li,   J.,   2008.   Organics   and   nitrogen   removal   and  sludge   stability   in   aerobic   granular   sludge   membrane   bioreactor.   Applied  Microbiology   and   Biotechnology   79   (4),   679–685.   doi: 10.10  07/s0  0253-0  08-  1466-6 .  Wang,   Q.,   Du,   G.,   Chen,   J.,   2004.   Aerobic   granular   sludge   cultivated   under   the   selec-  tive   pressure   as   a   driving   force.   Process   Biochemistry   39,   557–563.   doi: 10.1016/  S0  032-9592(03)0  0128-6 .  Wilén,   B.-M.,   Liébana,   R.,   Persson,   F.,   Modin,   O.,   Hermansson,   M.,   2018.   The   mecha-  nisms   of   granulation   of   activated   sludge   in   wastewater   treatment,   its   optimiza-  tion,   and   impact   on   effluent   quality.   Applied   Microbiology   and   Biotechnology  102   (12),   5005–5020.   doi: 10.10  07/s0  0253-  018-  8990-  9 .  Wójcik,   P.I.,   Kurdziel,   M.,   2019.   Training   neural   networks   on   high-dimensional   data  using   random   projection.   Pattern   Analysis   and   Applications   22   (3),   1221–1231.  doi: 10.1007/s10044-  018-  0697-  0 .  Ye,   Z.,   Yang,   J.,   Zhong,   N.,   Tu,   X.,   Jia,   J.,   Wang,   J.,   2020.   Tackling   environmental   chal-  lenges   in   pollution   controls   using   artificial   intelligence:   A   review.   Science   of   the  Total   Environment   699,   134279.   doi: 10.1016/j.scitotenv.2019.134279 .  Yilmaz,   G.,   Lemaire,   R.,   Keller,   J.,   Yuan,   Z.,   2008.   Simultaneous   nitrification,   den-  itrification,   and   phosphorus   removal   from   nutrient-rich   industrial   wastewa-  ter   using   granular   sludge.   Biotechnology   and   Bioengineering   100   (3),   529–541.  doi: 10.1002/bit.21774 .  Zaghloul,   M.S.,   Hamza,   R.A.,   Iorhemen,   O.T.,   Tay,   J.H.,   2018.   Performance   prediction  of   an   aerobic   granular   SBR   using   modular   multilayer   artificial   neural   networks.  Science   of   the   Total   Environment   645,   449–459.   doi: 10.1016/j.scitotenv.2018.07.  140 .  Zaghloul,   M.S.,   Hamza,   R.A.,   Iorhemen,   O.T.,   Tay,   J.H.,   Terna   Iorhemen,   O.,   Tay,   J.H.,  2020.   Comparison   of   adaptive   neuro-fuzzy   inference   systems   (ANFIS)   and   sup-  port   vector   regression   (SVR)   for   data-driven   modelling   of   aerobic   granular  sludge   reactors.   Journal   of   Environmental   Chemical   Engineering   8   (3),   103742.  doi: 10.1016/j.jece.2020.103742 .  Zheng,   S.,   Lu,   H.,   Zhang,   G.,   2020.   The   recent   development   of   the   aerobic   granular  sludge   for   industrial   wastewater   treatment:   a   mini   review.   Environmental   Tech-  nology   Reviews   9   (1),   55–66.   doi: 10.1080/21622515.2020.1732479 .  13
